{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40923621",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **1.** **Setup**\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cefd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f416d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(221)\n",
    "random.seed(221)\n",
    "np.random.seed(221)\n",
    "tf.random.set_seed(221)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1489a",
   "metadata": {},
   "source": [
    "## **1.1** Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f15595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train/val split data\n",
    "with open('train_val_split.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Store the data in variables\n",
    "x_train = data['x_train']\n",
    "x_val = data['x_val']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7f5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For EXTRA\n",
    "\n",
    "# Load the train/val split data without preprocessing\n",
    "with open('train_val_split_no_preproc.pkl', 'rb') as f:\n",
    "    data_no_preproc = pickle.load(f)\n",
    "\n",
    "# Convert DataFrames to list\n",
    "train_texts = data_no_preproc['x_train'].tolist()\n",
    "val_texts = data_no_preproc['x_val'].tolist()\n",
    "\n",
    "# Convert Series to list\n",
    "train_labels = data_no_preproc['y_train'].tolist()\n",
    "val_labels = data_no_preproc['y_val'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f24ae52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"X_train_te3s_embeddings.pkl\", \"rb\") as f:\n",
    "    X_train_te3s = pickle.load(f)\n",
    "\n",
    "with open(\"X_val_te3s_embeddings.pkl\", \"rb\") as f:\n",
    "    X_val_te3s = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55e9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"X_train_roberta_embeddings.pkl\", \"rb\") as f:\n",
    "    X_train_roberta = pickle.load(f)\n",
    "\n",
    "with open(\"X_val_roberta_embeddings.pkl\", \"rb\") as f:\n",
    "    X_val_roberta = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996a160",
   "metadata": {},
   "source": [
    "## **1.3** General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3198f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = x_train['text']\n",
    "\n",
    "#get list with lenghts of sentences\n",
    "train_len = []\n",
    "for i in corpus:\n",
    "    train_len.append(len(i))\n",
    "\n",
    "vector_size = max(train_len)\n",
    "\n",
    "metrics_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1d3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [word_tokenize(tweet.lower()) for tweet in x_train['text']]\n",
    "max_seq_len = max(len(tokens) for tokens in tokenized_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a2937c",
   "metadata": {},
   "source": [
    "## **1.4** Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd7bc1",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d2668b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'glove-twitter'\n",
    "glove_model = gensim.downloader.load(f'{model_name}-{emb_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42d87b",
   "metadata": {},
   "source": [
    "### Text Embeddings 3 Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf05a972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZURE_OPENAI_ENDPOINT: https://novaimsplayground.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "# EXTRA\n",
    "\n",
    "# Load variables from .env into environment\n",
    "load_dotenv()\n",
    "\n",
    "# Print environment variable\n",
    "print(\"AZURE_OPENAI_ENDPOINT:\", os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# Define embedding model\n",
    "model = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a00ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding model text embedding\n",
    "model_te3s = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a05b68",
   "metadata": {},
   "source": [
    "### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665a7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer for roberta\n",
    "model_name = \"cardiffnlp/twitter-roberta-base\"\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(model_name)\n",
    "model_roberta = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b8bdd",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1231d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(max_seq_len, vector_size))\n",
    "\n",
    "x = Masking(mask_value=0.0)(input_)\n",
    "x = Bidirectional(LSTM(units=units, return_sequences=False, dropout=dropout, recurrent_dropout=dropout))(x)\n",
    "x = Dropout(dropout)(x)\n",
    "output = Dense(num_class, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1020de10",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **2.** **Hyperparameter Tuning**\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0888fa",
   "metadata": {},
   "source": [
    "## **2.1** LR with RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eadbcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093de020",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.concatenate([X_train_roberta, X_val_roberta])\n",
    "y_combined = np.concatenate([y_train, y_val])\n",
    "test_fold = [-1]*len(X_train_roberta) + [0]*len(X_val_roberta)\n",
    "ps = PredefinedSplit(test_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6feac11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr_roberta = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"], \n",
    "    \"solver\": [\"lbfgs\", \"saga\"],\n",
    "    \"class_weight\": [\"balanced\"],\n",
    "    \"max_iter\": [ 200, 500], \n",
    "    \"multi_class\": [\"multinomial\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0aae700",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr_roberta = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_grid=param_grid_lr_roberta,\n",
    "    scoring='f1_macro',\n",
    "    cv=ps,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ae9754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7634 7630\n",
      "1909 1909\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_roberta), len(y_train))\n",
    "print(len(X_val_roberta), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d36240ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [9543, 9539]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgrid_lr_roberta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:922\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    919\u001b[39m estimator = \u001b[38;5;28mself\u001b[39m.estimator\n\u001b[32m    920\u001b[39m scorers, refit_metric = \u001b[38;5;28mself\u001b[39m._get_scorers()\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m X, y = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m params = _check_method_params(X, params=params)\n\u001b[32m    925\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._get_routed_params_for_fit(params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:514\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    485\u001b[39m \n\u001b[32m    486\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[32m    511\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    455\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    458\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    460\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [9543, 9539]"
     ]
    }
   ],
   "source": [
    "grid_lr_roberta.fit(X_combined, y_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c4f7c",
   "metadata": {},
   "source": [
    "## **2.2** LR with Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"elasticnet\"], \n",
    "    \"solver\": [\"saga\"],\n",
    "    \"class_weight\": [\"balanced\"],\n",
    "    \"max_iter\": [200, 500]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e884f2",
   "metadata": {},
   "source": [
    "## **2.3** XGBoost with Text Embedding 3 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43dd7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb_text3 = {\n",
    "    \"n_estimators\": [300, 500,1000],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.5, 0.7],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"gamma\": [0, 0.2, 0.5],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 0.5],\n",
    "    \"reg_lambda\": [1.0, 2.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ef396",
   "metadata": {},
   "source": [
    "## **2.4** Random Forest Bow Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83905560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03da179",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# **3.** **Final Predictions**\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1887dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "test_texts = test_data[\"text\"].tolist()\n",
    "\n",
    "# Get embeddings for test set\n",
    "X_test_roberta = np.array(get_roberta_embeddings(train_texts, \"X_test_roberta_embeddings.pkl\", batch_size=32, force_reload=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels with the trained classifier\n",
    "X_test_te3s_pred = clf_roberta_lr.predict(X_test_te3s)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_te3s = pd.DataFrame({\n",
    "    \"id\": test_data[\"id\"],\n",
    "    \"label\": X_test_roberta_pred\n",
    "})\n",
    "\n",
    "# Save submission to CSV\n",
    "submission_te3s.to_csv(\"roberta_lr_pred_25.csv\", index=False)\n",
    "print(\"Submission file saved as roberta_lr_pred_25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predictions from the saved CSV file\n",
    "pred_25 = pd.read_csv(\"roberta_lr_pred_25.csv\")\n",
    "pred_25.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
