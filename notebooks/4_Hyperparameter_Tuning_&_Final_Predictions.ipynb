{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "40923621",
      "metadata": {
        "id": "40923621"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **1.** **Setup**\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "2zMrOZ-75bUf",
        "outputId": "e2f579a8-623b-4779-b732-5e67b807ee02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "2zMrOZ-75bUf",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
            "Collecting ftfy (from -r requirements.txt (line 5))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting emoji (from -r requirements.txt (line 6))\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting python-dotenv (from -r requirements.txt (line 7))\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.13.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.9.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (5.24.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (5.10.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (3.9.1)\n",
            "Collecting langdetect (from -r requirements.txt (line 18))\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting contractions (from -r requirements.txt (line 19))\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (1.6.1)\n",
            "Collecting keras-preprocessing (from -r requirements.txt (line 23))\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting imblearn (from -r requirements.txt (line 24))\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.1.4)\n",
            "Collecting gensim (from -r requirements.txt (line 30))\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (1.7.0)\n",
            "Collecting tensorflow==2.15.0 (from -r requirements.txt (line 36))\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (2.18.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (1.84.0)\n",
            "Collecting optuna (from -r requirements.txt (line 43))\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 46)) (2.14.4)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (4.52.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0->-r requirements.txt (line 36))\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0->-r requirements.txt (line 36))\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (4.14.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0->-r requirements.txt (line 36))\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 36)) (1.72.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0->-r requirements.txt (line 36))\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0->-r requirements.txt (line 36))\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0->-r requirements.txt (line 36))\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->-r requirements.txt (line 13)) (9.1.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->-r requirements.txt (line 14)) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->-r requirements.txt (line 14)) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->-r requirements.txt (line 14)) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->-r requirements.txt (line 14)) (5.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->-r requirements.txt (line 17)) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->-r requirements.txt (line 17)) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->-r requirements.txt (line 17)) (2024.11.6)\n",
            "Collecting textsearch>=0.0.21 (from contractions->-r requirements.txt (line 19))\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 22)) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 22)) (3.6.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (from imblearn->-r requirements.txt (line 24)) (0.13.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->-r requirements.txt (line 27)) (2.21.5)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn->-r requirements.txt (line 22))\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->-r requirements.txt (line 30)) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 31)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 31)) (0.32.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 31)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 31)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 31)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 31)) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 32)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 32)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 32)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 32)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 32)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 32))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 32)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 32)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 32)) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->-r requirements.txt (line 33)) (5.9.5)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras (from -r requirements.txt (line 37))\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 40)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 40)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 40)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 40)) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 40)) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 40)) (1.3.1)\n",
            "Collecting alembic>=1.5.0 (from optuna->-r requirements.txt (line 43))\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna->-r requirements.txt (line 43))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->-r requirements.txt (line 43)) (2.0.41)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 46)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 46)) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 46)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 46)) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 46)) (3.11.15)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->-r requirements.txt (line 43)) (1.1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 40)) (3.10)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0->-r requirements.txt (line 36)) (0.45.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 46)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 46)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 46)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 46)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 46)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 46)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 46)) (1.20.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 40)) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 40)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 40)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]->-r requirements.txt (line 31)) (1.1.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->-r requirements.txt (line 14)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->-r requirements.txt (line 14)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->-r requirements.txt (line 14)) (0.25.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->-r requirements.txt (line 14)) (4.3.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 40)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 40)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 40)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]->-r requirements.txt (line 31)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]->-r requirements.txt (line 31)) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->-r requirements.txt (line 43)) (3.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (3.1.3)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions->-r requirements.txt (line 19))\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions->-r requirements.txt (line 19))\n",
            "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn->-r requirements.txt (line 24)) (0.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 32)) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r requirements.txt (line 36)) (3.2.2)\n",
            "Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=686f3ac7c72b668ddb3f0b683636c6e3274d64d880e9db4eac97542781a5e353\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: wrapt, tensorflow-estimator, python-dotenv, pyahocorasick, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, langdetect, keras, ftfy, emoji, colorlog, anyascii, textsearch, scipy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, ml-dtypes, keras-preprocessing, alembic, optuna, nvidia-cusolver-cu12, gensim, contractions, tensorboard, tensorflow, tf-keras, imblearn\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.18.0\n",
            "    Uninstalling tf_keras-2.18.0:\n",
            "      Successfully uninstalled tf_keras-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.16.1 anyascii-0.3.2 colorlog-6.9.0 contractions-0.1.73 emoji-2.14.1 ftfy-6.3.1 gensim-4.3.3 imblearn-0.0 keras-2.15.0 keras-preprocessing-1.1.2 langdetect-1.0.9 ml-dtypes-0.2.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.3.0 protobuf-4.25.8 pyahocorasick-2.1.0 python-dotenv-1.1.0 scipy-1.13.1 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 textsearch-0.0.24 tf-keras-2.15.1 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "7cd99b7770d34686b92e01ec34fedb02"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1cefd779",
      "metadata": {
        "id": "1cefd779"
      },
      "outputs": [],
      "source": [
        "from utils import *\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b5f416d8",
      "metadata": {
        "id": "b5f416d8"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(221)\n",
        "random.seed(221)\n",
        "np.random.seed(221)\n",
        "tf.random.set_seed(221)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbe1489a",
      "metadata": {
        "id": "fbe1489a"
      },
      "source": [
        "## **1.1** Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1f15595d",
      "metadata": {
        "id": "1f15595d"
      },
      "outputs": [],
      "source": [
        "# Load the train/val split data\n",
        "with open('train_val_split.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# Store the data in variables\n",
        "x_train = data['x_train']\n",
        "x_val = data['x_val']\n",
        "y_train = data['y_train']\n",
        "y_val = data['y_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1f7f5543",
      "metadata": {
        "id": "1f7f5543"
      },
      "outputs": [],
      "source": [
        "# For EXTRA\n",
        "\n",
        "# Load the train/val split data without preprocessing\n",
        "with open('train_val_split_no_preproc.pkl', 'rb') as f:\n",
        "    data_no_preproc = pickle.load(f)\n",
        "\n",
        "# Convert DataFrames to list\n",
        "train_texts = data_no_preproc['x_train'].tolist()\n",
        "val_texts = data_no_preproc['x_val'].tolist()\n",
        "\n",
        "# Convert Series to list\n",
        "train_labels = data_no_preproc['y_train'].tolist()\n",
        "val_labels = data_no_preproc['y_val'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3262c5e3",
      "metadata": {
        "id": "3262c5e3"
      },
      "source": [
        "## **1.2** Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ab9ed8f8",
      "metadata": {
        "id": "ab9ed8f8"
      },
      "outputs": [],
      "source": [
        "# ------- Parameters -------\n",
        "# Glove\n",
        "emb_size = 200 # start small than increase to find the best value\n",
        "\n",
        "# TF-IDF\n",
        "max_df = 0.8 # we are removing terms that appear in >80% of tweets\n",
        "\n",
        "# Word2Vec\n",
        "window = 2         # context window size\n",
        "min_count = 1      # minimum word frequency to include"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5996a160",
      "metadata": {
        "id": "5996a160"
      },
      "source": [
        "## **1.3** General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3198f952",
      "metadata": {
        "id": "3198f952"
      },
      "outputs": [],
      "source": [
        "corpus = x_train['text']\n",
        "\n",
        "#get list with lenghts of sentences\n",
        "train_len = []\n",
        "for i in corpus:\n",
        "    train_len.append(len(i))\n",
        "\n",
        "vector_size = max(train_len)\n",
        "\n",
        "metrics_df = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt', download_dir='/Users/mgalao/nltk_data')\n",
        "nltk.data.path.append('/Users/mgalao/nltk_data')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "EuVOQxq56qa1",
        "outputId": "09b7b260-f34c-44a7-ff51-a4a1d4878600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EuVOQxq56qa1",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/mgalao/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ed1d3995",
      "metadata": {
        "id": "ed1d3995"
      },
      "outputs": [],
      "source": [
        "tokenized_train = [word_tokenize(tweet.lower()) for tweet in x_train['text']]\n",
        "max_seq_len = max(len(tokens) for tokens in tokenized_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a2937c",
      "metadata": {
        "id": "a3a2937c"
      },
      "source": [
        "## **1.4** Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3dd7bc1",
      "metadata": {
        "id": "a3dd7bc1"
      },
      "source": [
        "### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2668b6",
      "metadata": {
        "id": "4d2668b6"
      },
      "outputs": [],
      "source": [
        "model_name = 'glove-twitter'\n",
        "glove_model = gensim.downloader.load(f'{model_name}-{emb_size}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b42d87b",
      "metadata": {
        "id": "3b42d87b"
      },
      "source": [
        "### Text Embeddings 3 Small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf05a972",
      "metadata": {
        "id": "cf05a972"
      },
      "outputs": [],
      "source": [
        "# EXTRA\n",
        "\n",
        "# Load variables from .env into environment\n",
        "load_dotenv()\n",
        "\n",
        "# Print environment variable\n",
        "print(\"AZURE_OPENAI_ENDPOINT:\", os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
        "\n",
        "# Initialize Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
        "    api_version=\"2024-02-01\",\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        ")\n",
        "\n",
        "# Define embedding model\n",
        "model = \"text-embedding-3-small\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a00ad0b",
      "metadata": {
        "id": "2a00ad0b"
      },
      "outputs": [],
      "source": [
        "# Define embedding model text embedding\n",
        "model_te3s = \"text-embedding-3-small\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3a05b68",
      "metadata": {
        "id": "e3a05b68"
      },
      "source": [
        "### Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "665a7d5d",
      "metadata": {
        "id": "665a7d5d"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model and tokenizer for roberta\n",
        "model_name = \"cardiffnlp/twitter-roberta-base\"\n",
        "tokenizer_roberta = AutoTokenizer.from_pretrained(model_name)\n",
        "model_roberta = AutoModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461b8bdd",
      "metadata": {
        "id": "461b8bdd"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db1231d9",
      "metadata": {
        "id": "db1231d9"
      },
      "outputs": [],
      "source": [
        "input_ = Input(shape=(max_seq_len, vector_size))\n",
        "\n",
        "x = Masking(mask_value=0.0)(input_)\n",
        "x = Bidirectional(LSTM(units=units, return_sequences=False, dropout=dropout, recurrent_dropout=dropout))(x)\n",
        "x = Dropout(dropout)(x)\n",
        "output = Dense(num_class, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1020de10",
      "metadata": {
        "id": "1020de10"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **2.** **Hyperparameter Tuning**\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a0888fa",
      "metadata": {
        "id": "8a0888fa"
      },
      "source": [
        "## **2.1** LR with Text Embedding 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdece002",
      "metadata": {
        "id": "bdece002"
      },
      "source": [
        "### **2.1.1** Running Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81517608",
      "metadata": {
        "id": "81517608"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e13a7b2e",
      "metadata": {
        "id": "e13a7b2e"
      },
      "outputs": [],
      "source": [
        "X_train_te3s, X_val_te3s, y_train_pred_te3s, y_val_pred_te3s = embedding_te3s(\n",
        "    train_texts=train_texts,\n",
        "    train_labels=train_labels,\n",
        "    val_texts=val_texts,\n",
        "    cache_file_train=\"X_train_te3s_embeddings.pkl\",\n",
        "    cache_file_val=\"X_val_te3s_embeddings.pkl\",\n",
        "    client=client,\n",
        "    model_te3s=model_te3s,\n",
        "    batch_size=32,\n",
        "    model=model\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e67936d",
      "metadata": {
        "id": "1e67936d"
      },
      "outputs": [],
      "source": [
        "X_combined = np.vstack([X_train_te3s, X_val_te3s])\n",
        "y_combined = np.concatenate([train_labels, val_labels])\n",
        "\n",
        "split_index = [-1]*len(X_train_te3s) + [0]*len(X_val_te3s)\n",
        "ps = PredefinedSplit(test_fold=split_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0102c405",
      "metadata": {
        "id": "0102c405"
      },
      "outputs": [],
      "source": [
        "param_grid = [\n",
        "    {'penalty': ['l1'], 'solver': ['saga'], 'C': [0.01, 0.1, 1, 10],\n",
        "     'class_weight': [None, 'balanced'], 'multi_class': ['ovr', 'multinomial']},\n",
        "\n",
        "    {'penalty': ['l2'], 'solver': ['saga'], 'C': [0.01, 0.1, 1, 10],\n",
        "     'class_weight': [None, 'balanced'], 'multi_class': ['ovr', 'multinomial']},\n",
        "\n",
        "    {'penalty': ['elasticnet'], 'solver': ['saga'], 'C': [0.01, 0.1, 1, 10],\n",
        "     'l1_ratio': [0.0, 0.5, 1.0], 'class_weight': [None, 'balanced'], 'multi_class': ['ovr', 'multinomial']}\n",
        "]\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1_macro',  # ou outro scoring adequado\n",
        "    cv=ps,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    error_score='raise'\n",
        ")\n",
        "\n",
        "grid.fit(X_combined, y_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888e84f7",
      "metadata": {
        "id": "888e84f7"
      },
      "outputs": [],
      "source": [
        "grid.best_params_\n",
        "grid.best_score_\n",
        "grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "435dc50e",
      "metadata": {
        "id": "435dc50e"
      },
      "outputs": [],
      "source": [
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32b5e5b8",
      "metadata": {
        "id": "32b5e5b8"
      },
      "outputs": [],
      "source": [
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d27d342",
      "metadata": {
        "id": "4d27d342"
      },
      "source": [
        "### **2.1.2** Assess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ea47a7",
      "metadata": {
        "id": "38ea47a7"
      },
      "outputs": [],
      "source": [
        "model_lr = LogisticRegression( penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.4,\n",
        "    C=10,\n",
        "    class_weight=None,\n",
        "    max_iter=1000,\n",
        "    multi_class='ovr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ebf3eb7",
      "metadata": {
        "id": "9ebf3eb7"
      },
      "outputs": [],
      "source": [
        "title = \"Logistic Regression with Text Embedding 3 Small\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "822b01e7",
      "metadata": {
        "id": "822b01e7"
      },
      "outputs": [],
      "source": [
        "X_train_te3s,X_val_te3s,y_train_pred_te3s,y_val_pred_te3s = embedding_te3s(train_texts=train_texts,\n",
        "                                                                 train_labels=train_labels,\n",
        "                                                                 val_texts = val_texts,\n",
        "                                                                 cache_file_train=\"X_train_te3s_embeddings.pkl\",\n",
        "                                                                 cache_file_val=\"X_val_te3s_embeddings.pkl\",\n",
        "                                                                 client=client,\n",
        "                                                                 model_te3s=model_te3s,\n",
        "                                                                 batch_size=32,\n",
        "                                                                 model=model_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ffc280",
      "metadata": {
        "id": "a9ffc280"
      },
      "outputs": [],
      "source": [
        "get_metrics_df(title, train_labels, y_train_pred_te3s, val_labels, y_val_pred_te3s)\n",
        "plot_metrics(train_labels, y_train_pred_te3s, val_labels, y_val_pred_te3s, title=title)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce09137",
      "metadata": {
        "id": "8ce09137"
      },
      "source": [
        "## **2.2** XGB with Text Embedding 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82dc8e14",
      "metadata": {
        "id": "82dc8e14"
      },
      "source": [
        "### **2.2.1** Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0dafa69",
      "metadata": {
        "id": "e0dafa69"
      },
      "outputs": [],
      "source": [
        "xgb = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=3,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26b79f7",
      "metadata": {
        "id": "f26b79f7"
      },
      "outputs": [],
      "source": [
        "param_grid_xgb = {\n",
        "    'learning_rate': [0.2, 0.1],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'n_estimators': [100, 500],\n",
        "    'subsample': [0.7,1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'scale_pos_weight': [1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5947933",
      "metadata": {
        "id": "c5947933"
      },
      "outputs": [],
      "source": [
        "X_train_te3s, X_val_te3s, y_train_pred_te3s, y_val_pred_te3s = embedding_te3s(\n",
        "    train_texts=train_texts,\n",
        "    train_labels=train_labels,\n",
        "    val_texts=val_texts,\n",
        "    cache_file_train=\"X_train_te3s_embeddings.pkl\",\n",
        "    cache_file_val=\"X_val_te3s_embeddings.pkl\",\n",
        "    client=client,\n",
        "    model_te3s=model_te3s,\n",
        "    batch_size=32,\n",
        "    model=xgb\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc8d8ad",
      "metadata": {
        "id": "2cc8d8ad"
      },
      "outputs": [],
      "source": [
        "X_combined = np.vstack([X_train_te3s, X_val_te3s])\n",
        "y_combined = np.concatenate([train_labels, val_labels])\n",
        "\n",
        "split_index = [-1]*len(X_train_te3s) + [0]*len(X_val_te3s)\n",
        "ps = PredefinedSplit(test_fold=split_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf21e24e",
      "metadata": {
        "id": "cf21e24e"
      },
      "outputs": [],
      "source": [
        "grid_xgb = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid_xgb,\n",
        "    scoring='f1_macro',\n",
        "    cv=ps,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    error_score='raise'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba8bee9",
      "metadata": {
        "id": "7ba8bee9"
      },
      "outputs": [],
      "source": [
        "grid_xgb.fit(X_combined, y_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b81d35",
      "metadata": {
        "id": "92b81d35"
      },
      "source": [
        "### **2.2.2** Assess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db44e39e",
      "metadata": {
        "id": "db44e39e"
      },
      "outputs": [],
      "source": [
        "print(grid_xgb.best_params_)\n",
        "print(grid_xgb.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f044eb",
      "metadata": {
        "id": "90f044eb"
      },
      "outputs": [],
      "source": [
        "xgb = XGBClassifier(\n",
        "    colsample_bytree= 0.8,\n",
        "    learning_rate = 0.2,\n",
        "    max_depth = 4,\n",
        "    n_estimators = 500, scale_pos_weight= 1, subsample = 0.7,\n",
        "    num_class=3,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7686be33",
      "metadata": {
        "id": "7686be33"
      },
      "outputs": [],
      "source": [
        "title = \"XGB with Text Embedding 3 Small\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a24ea9",
      "metadata": {
        "id": "a3a24ea9"
      },
      "outputs": [],
      "source": [
        "X_train_te3s,X_val_te3s,y_train_pred_te3s,y_val_pred_te3s = embedding_te3s(train_texts=train_texts,\n",
        "                                                                 train_labels=train_labels,\n",
        "                                                                 val_texts = val_texts,\n",
        "                                                                 cache_file_train=\"X_train_te3s_embeddings.pkl\",\n",
        "                                                                 cache_file_val=\"X_val_te3s_embeddings.pkl\",\n",
        "                                                                 client=client,\n",
        "                                                                 model_te3s=model_te3s,\n",
        "                                                                 batch_size=32,\n",
        "                                                                 model=xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c773018",
      "metadata": {
        "id": "7c773018"
      },
      "outputs": [],
      "source": [
        "get_metrics_df(title, train_labels, y_train_pred_te3s, val_labels, y_val_pred_te3s)\n",
        "plot_metrics(train_labels, y_train_pred_te3s, val_labels, y_val_pred_te3s, title=title)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61d103e6",
      "metadata": {
        "id": "61d103e6"
      },
      "source": [
        "## **2.3** LSTM with Glove"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbafa1ef",
      "metadata": {
        "id": "dbafa1ef"
      },
      "source": [
        "### **2.3.1** Running model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32766606",
      "metadata": {
        "id": "32766606"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "units_list = [64, 128]\n",
        "dropout_list = [0.3, 0.4]\n",
        "lr_list = [0.005, 0.001]\n",
        "\n",
        "best_f1 = 0\n",
        "best_params = {}\n",
        "\n",
        "for units in units_list:\n",
        "    for dropout in dropout_list:\n",
        "        for lr in lr_list:\n",
        "            print(f\"\\n Testing units={units}, dropout={dropout}, lr={lr}\")\n",
        "\n",
        "            input_ = Input(shape=(26, 200))\n",
        "            x = Masking(mask_value=0.0)(input_)\n",
        "            x = Bidirectional(LSTM(units=units, return_sequences=False, dropout=dropout, recurrent_dropout=dropout))(x)\n",
        "            x = Dropout(dropout)(x)\n",
        "            output = Dense(3, activation='softmax')(x)\n",
        "            optimizer = Adam(learning_rate=lr)\n",
        "            model_lstm = Model(inputs=input_, outputs=output)\n",
        "            model_lstm.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                               metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "            # Train and evaluate\n",
        "            _, _, y_val_pred = embedding_glove_lstm(\n",
        "                x_train=x_train,\n",
        "                y_train=y_train,\n",
        "                x_val=x_val,\n",
        "                y_val=y_val,\n",
        "                model_glove=glove_model,\n",
        "                emb_size=200,\n",
        "                model_lstm=model_lstm,\n",
        "                n_classes=3,\n",
        "                batch_size=32,\n",
        "                epochs=15\n",
        "            )\n",
        "\n",
        "            f1 = f1_score(y_val, y_val_pred, average='macro')\n",
        "            print(f\" Val F1 Score: {f1:.4f}\")\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_params = {'units': units, 'dropout': dropout, 'learning_rate': lr}\n",
        "\n",
        "print(\"\\nBest Params:\", best_params)\n",
        "print(f\"Best Val F1: {best_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc693f6",
      "metadata": {
        "id": "1bc693f6"
      },
      "source": [
        "### **2.3.2** Assessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95239f94",
      "metadata": {
        "id": "95239f94"
      },
      "outputs": [],
      "source": [
        "input_ = Input(shape=(26, 200))\n",
        "x = Masking(mask_value=0.0)(input_)\n",
        "x = Bidirectional(LSTM(units=128, return_sequences=False, dropout=dropout, recurrent_dropout=dropout))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "optimizer=Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67632341",
      "metadata": {
        "id": "67632341"
      },
      "outputs": [],
      "source": [
        "metrics=['categorical_accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc', multi_label=True)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6881da6",
      "metadata": {
        "id": "d6881da6"
      },
      "outputs": [],
      "source": [
        "model_lstm = Model(inputs=input_, outputs=output)\n",
        "model_lstm.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=metrics)\n",
        "\n",
        "X_train_glove, y_train_pred_glove, y_val_pred_glove = embedding_glove_lstm(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val, model_glove = glove_model, n_classes=3, batch_size=16, epochs=15, emb_size=emb_size, model_lstm=model_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f94e210",
      "metadata": {
        "id": "1f94e210"
      },
      "outputs": [],
      "source": [
        "title = \"LSTM Glove\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff13152",
      "metadata": {
        "id": "2ff13152"
      },
      "outputs": [],
      "source": [
        "get_metrics_df(title, y_train, y_train_pred_glove, y_val, y_val_pred_glove)\n",
        "\n",
        "# Plot metrics\n",
        "plot_metrics(y_train, y_train_pred_glove, y_val, y_val_pred_glove, title=title)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e884f2",
      "metadata": {
        "id": "50e884f2"
      },
      "source": [
        "## **2.4** RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9066c247",
      "metadata": {
        "id": "9066c247",
        "outputId": "862dbba4-ad56-4a18-99f8-feefdecb8859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "8652526a415d4c1bb0cc5ea1e2a42bf0",
            "5af02d5492df486eb12e88d712076199",
            "c36e4de72b1b4b17ac6ee067e3fd7528",
            "3b90b2cae9b14e8999c103762f69beb6",
            "1d2ceff3aa514da98ccb4f4725221e74",
            "c2fd7c4e1ae04430b5340cc2e2692341",
            "7f444f24985b4158ad86c47658cfc0b4",
            "a2767b3cd11e4a90be3e55d4abe5d32f",
            "ac050e4a28b540fd8d4e54f9c0fff20f",
            "e01b0005093747b685a5004b195b5a65",
            "e134225350f74870817564cad3be4050",
            "22642c6ab81a4f56adbf9afda84b2742",
            "822a25ec3b984919ae550c3a93447e21",
            "dea8aabee8914949a6c7d3f448e59b46",
            "718f7b5a4481451ea7d8305908ed86fb",
            "32c084f21c9a44f791e914dd691ae6ec",
            "764201c467884bd4aa0239977c1779eb",
            "f7803a57344449bfa56a2906824ac700",
            "9dada733478241dbb6212c3489af7ddd",
            "2b1e09ce806549b3ae162d63090d5fc2",
            "d5af9c3cc9c748aa9684da72d7fa5aac",
            "243004813737486d9ed0ef33a6a535e8",
            "563ab7e79e1e4d90ab93c7458e68a206",
            "3b6706d5815e4ed18a1d53dd0ea300b6",
            "31bd11198dd647f9992af27bc58663f1",
            "a0426b13ffeb40c29bc41ae76eef778c",
            "6ec3b8a77f614f419e895e919488774f",
            "01f793e12e954d77bd510dc2a2f73504",
            "b42dcc4389004c69b9a7f0e24d0c613a",
            "ab000a4cabc7405f942c46018c2a8d5f",
            "56bc2282a5c04b048e63b8a290a771e5",
            "6fd5bd21a7224d80b57d7020d7a4f44c",
            "1bfb359b888049098f3035c9a8d324a8",
            "22f1857826d74eb28c79b87e88f3e96f",
            "b3b69be265b54da5b252d39407a1086e",
            "4f903aa67a544f24989ff7c52fcca017",
            "fd9662a3f97a48c6bac159be44714bd8",
            "a21af05d32084e34a9dd91559d9f98a5",
            "120eb0a5883c4df3b13ed4c69942b9a7",
            "03e069f1b8bd45c1922deacb065b3199",
            "79e78c97bf95468997519ecefdf5e8cd",
            "20aaacf704ce45fbb7ace72ece95c2d9",
            "dc0874a1811648c69a3b94e8f93ea5ce",
            "1df74b761ce340dd9789b3a32a7b6996"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8652526a415d4c1bb0cc5ea1e2a42bf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22642c6ab81a4f56adbf9afda84b2742"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "563ab7e79e1e4d90ab93c7458e68a206"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22f1857826d74eb28c79b87e88f3e96f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Tokenizer & Model\n",
        "checkpoint = \"cardiffnlp/twitter-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3, hidden_dropout_prob=0.3, attention_probs_dropout_prob=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"],truncation=True)"
      ],
      "metadata": {
        "id": "95ndXhaA8Pvm"
      },
      "id": "95ndXhaA8Pvm",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2f5a66bf",
      "metadata": {
        "id": "2f5a66bf",
        "outputId": "620f7f95-e3d7-490b-9868-cdcc32b0c10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "1063d3ca8d7944c5b26cfa8a086d20d4",
            "da47443854144949aa55b6a14182cdb8",
            "3701e0ce90f2487fbd6fe48e06d66be6",
            "f6205addc9084f3b80d931318b590f45",
            "6c8580a8999348f798dae83165ad73cb",
            "a248cd7030934f7ab6017b1ce18d1f1c",
            "8e219413361f499fab71476fa3f0727f",
            "804881289c234d2ebbdf89c24875e5d1",
            "ba82667307f84792a4ebd473b93e35a9",
            "1b8c5a01ff1f42ed99d95b0af499546d",
            "dcd1d0b482c84fb1a4947c59f6e8ba60",
            "f612896c7bb649d187d63529f2ce1bb0",
            "30175b61227d4a3abb4e1e4ec7650f5e",
            "50abf622a6cd45fc909a5f40f35d0b0e",
            "151162f8d1a3437193e732c6ee113b2c",
            "8b62ca14580f43689eaee31d727754d0",
            "a251b2f8a7964d35824319f5d3d89a26",
            "6571afeefde4448abe78706dba974bfb",
            "7cc0312b87a24c21acf0227f3d2ea861",
            "e1675575dc3e43da90abf1a627fea230",
            "cb9441dfd17343df835fa80aac6a6c50",
            "794627cd93d54f478515b66ba0aaaa40",
            "0cea4be600a740fdb9c2594e62840b2f",
            "6195c30992fa470f8e670dc21ff72539",
            "c51c1d10ddce478cbd9df4fe2d87f5da",
            "0b1904d18dee46e6862846ec34f3a408",
            "47421a189993489097126178f3e15383",
            "27c9a826cccf4a4d8b61c734405b0977",
            "e70b4a1e2ba64a75aa9fc7b53e249919",
            "f1dd713695184a919c7e901ae7bb1bfb",
            "d549f71a0c57477088fe3068f864074e",
            "e72df9e13fe24feaba5594f723ee1fe2",
            "e280b9d0c85b47e594467f80d61d7ae8"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7634 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1063d3ca8d7944c5b26cfa8a086d20d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f612896c7bb649d187d63529f2ce1bb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1909 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cea4be600a740fdb9c2594e62840b2f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Tokenize and convert to Dataset\n",
        "train_ds = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels}).map(tokenize, batched=True)\n",
        "val_ds = Dataset.from_dict({\"text\": val_texts, \"label\": val_labels}).map(tokenize, batched=True)\n",
        "dataset = DatasetDict({\"train\": train_ds, \"validation\": val_ds})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6dde1b25",
      "metadata": {
        "id": "6dde1b25"
      },
      "outputs": [],
      "source": [
        "# Model init with weighted loss\n",
        "def model_init():\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
        "    class_weights = torch.tensor(\n",
        "        np.bincount(train_labels, minlength=3) / len(train_labels),\n",
        "        dtype=torch.float\n",
        "    )\n",
        "    class_weights = 1.0 / class_weights\n",
        "    model.classifier.loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "44859808",
      "metadata": {
        "id": "44859808"
      },
      "outputs": [],
      "source": [
        "# Search space\n",
        "def hp_space(trial: Trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 4, 10),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.0, 0.2)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e995fa8d",
      "metadata": {
        "id": "e995fa8d"
      },
      "outputs": [],
      "source": [
        "# Training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"no\",\n",
        "    save_strategy=\"no\",\n",
        "    save_total_limit=1,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=[]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b0e912a4",
      "metadata": {
        "id": "b0e912a4",
        "outputId": "ab8d56f8-c97f-4c9c-9194-95b4a17ec920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-4025623868>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Trainer for tuning\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics_transformers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "eeeef5dd",
      "metadata": {
        "id": "eeeef5dd",
        "outputId": "140e5c0b-68cf-43b8-8a24-c099c02276ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 12:31:50,875] A new study created in memory with name: no-name-c0064f60-4def-4c29-a5cb-b559099c2cd8\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1912' max='1912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1912/1912 10:14, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.425800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.365600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.330900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.237400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.247400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.175300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.160500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.109900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.095800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.082900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.057300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.051200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.057000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3585' max='239' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [239/239 3:06:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 12:42:15,207] Trial 0 finished with value: 3.4438959231005843 and parameters: {'learning_rate': 1.4631175255058158e-05, 'num_train_epochs': 8, 'weight_decay': 0.28207264263577014, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.16094112503198427}. Best is trial 0 with value: 3.4438959231005843.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8595' max='8595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8595/8595 16:09, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.937700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.773500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.607600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.443300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.520900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.379800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.400200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.401500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.393800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.434900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.388800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.441000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.456800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.378500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.383800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.293200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.286800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.254700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.323200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.277300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.296500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.313500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.376400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.331500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.248700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.180300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.200800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.214900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.205400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.244400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.173900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.204200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.261700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.226000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.183900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.127600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.165600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.174800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.114400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.113900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.161300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.148300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.138000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.133300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.088400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.084300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.126500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.085400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.126400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.064300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.042100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.054100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.068600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.081600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.079500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.080400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.048600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.048000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.053700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.096000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.038800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.043600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.056000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.042100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.033400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.044500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.026900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.031600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.072800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 12:58:33,024] Trial 1 finished with value: 3.4728897087881943 and parameters: {'learning_rate': 1.0166879716534652e-05, 'num_train_epochs': 9, 'weight_decay': 0.24877117888506198, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.16344589524569564}. Best is trial 1 with value: 3.4728897087881943.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9550' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9550/9550 17:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.046600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.876300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.671700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.493800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.486300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.471100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.513900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.469300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.490100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.360500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.353400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.343500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.314300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.402700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.320600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.459400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.371000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.343700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.325700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.215700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.227600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.213900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.221400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.263500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.243600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.236800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.160500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.111200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.120700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.171500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.131300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.102300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.185600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.181900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.122500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.072000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.082600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.100200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.107400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.085900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.052200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.127400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.104700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.105800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.054900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.040200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.057400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.094400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.054500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.060500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.061900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.044500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.049100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.031000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.062300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.056600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.030100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.033100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.046800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.037100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.061500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.022100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.015200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.036900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.023900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.025100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.027800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.020800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.013900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.026300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.016400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.035400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.009600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.034300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 13:16:34,230] Trial 2 finished with value: 3.4976335275686563 and parameters: {'learning_rate': 1.640399981885772e-05, 'num_train_epochs': 10, 'weight_decay': 0.09660987697403407, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.05556759396116082}. Best is trial 2 with value: 3.4976335275686563.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2868' max='2868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2868/2868 08:38, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.951800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.587100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.444900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.425000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.370900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.288400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.302600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.275400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.280900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.218100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.159400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.180400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.205600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.181800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.123900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.100900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.120700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.091800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.091000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.072500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.097800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.055900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.043300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.061100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.065100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 13:25:20,731] Trial 3 finished with value: 3.4925368189605885 and parameters: {'learning_rate': 1.632399334497078e-05, 'num_train_epochs': 6, 'weight_decay': 0.17584111225542307, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.045521242418919}. Best is trial 2 with value: 3.4976335275686563.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2868' max='2868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2868/2868 08:37, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.893600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.540100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.445400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.413000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.360800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.275000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.269900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.204000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.157600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.163600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.211900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.151700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.112400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.104500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.091300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.106100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.105000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.070600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.077400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.041100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.035800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.023500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.036500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.022000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 13:34:06,861] Trial 4 finished with value: 3.4737001673552776 and parameters: {'learning_rate': 2.3545269542147387e-05, 'num_train_epochs': 6, 'weight_decay': 0.05773188390512474, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.0361988519978133}. Best is trial 2 with value: 3.4976335275686563.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2868' max='2868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2868/2868 08:37, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.946200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.585200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.453200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.432700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.369100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.285400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.279000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.268200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.271500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.203200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.136000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.182000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.192500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.165400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.089500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.103500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.100600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.121000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.104400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.077700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.041800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.053200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.024400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.052000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.038700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 13:42:53,055] Trial 5 finished with value: 3.4673508257880292 and parameters: {'learning_rate': 2.2528166063717887e-05, 'num_train_epochs': 6, 'weight_decay': 0.21796117236391266, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.05842855674114844}. Best is trial 2 with value: 3.4976335275686563.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1195' max='1195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1195/1195 06:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.870600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.483400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.382500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.302800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.260100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.156300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.182400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.095400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.082200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.041900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 13:49:27,966] Trial 6 finished with value: 3.4805120482791723 and parameters: {'learning_rate': 4.3500898729890286e-05, 'num_train_epochs': 5, 'weight_decay': 0.2883744064309579, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.1764670846664466}. Best is trial 2 with value: 3.4976335275686563.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8595' max='8595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8595/8595 16:04, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.955200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.780500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.600400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.492100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.524100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.466300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.394100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.363400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.397000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.371700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.444000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.392700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.454600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.443800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.379300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.378100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.252600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.269200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.253300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.296700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.266000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.286700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.316600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.304200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.179400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.142900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.120600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.190400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.139000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.182000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.163100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.179400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.193600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.103000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.103500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.093500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.112700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.103300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.118600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.088400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.092500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.063700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.028600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.095100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.039200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.028200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.076900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.041300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.022000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.024400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.034600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.029200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.019900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.027300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.017100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.023100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.010200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.037400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.020600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 14:05:40,861] Trial 7 finished with value: 3.4700972116684445 and parameters: {'learning_rate': 2.0243118580308745e-05, 'num_train_epochs': 9, 'weight_decay': 0.2169001413350123, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.13989475481987254}. Best is trial 2 with value: 3.4976335275686563.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3346' max='3346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3346/3346 10:04, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.669900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.464600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.437200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.386000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.307400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.324600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.285200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.306500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.245400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.169400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.218600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.222300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.198700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.155100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.142600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.123500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.141000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.136900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.093900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.117200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.105200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.090400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.063500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.042500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.056500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.054100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.030700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.049100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.044200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 14:15:53,736] Trial 8 finished with value: 3.478042713837636 and parameters: {'learning_rate': 1.3742664403034002e-05, 'num_train_epochs': 7, 'weight_decay': 0.1588971533761899, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.0618631917473034}. Best is trial 2 with value: 3.4976335275686563.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4302' max='4302' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4302/4302 12:56, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.824200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.527900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.427400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.413800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.376800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.283100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.306000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.283500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.294400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.236100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.171200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.198600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.231000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.188900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.161500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.162000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.155400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.142600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.112600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.127600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.109600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.074300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.063300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.060500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.089700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.077700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.074100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.048900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.050400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.056700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.047300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.022100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.013700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.036800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.031700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.018500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.036500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 14:28:59,023] Trial 9 finished with value: 3.4462840197255367 and parameters: {'learning_rate': 1.2505111965645036e-05, 'num_train_epochs': 9, 'weight_decay': 0.2909703088704006, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.0023996003112882972}. Best is trial 2 with value: 3.4976335275686563.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9550' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9550/9550 17:53, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.042700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.860900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.661500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.500100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.472500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.480400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.501300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.462000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.502200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.404400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.429700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.451900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.365800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.440500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.366400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.460600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.439500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.352500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.387700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.270800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.257200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.233800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.242000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.302800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.293100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.282100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.286300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.298400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.204500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.130700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.176100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.179800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.121200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.197800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.200700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.178100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.184500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.108800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.084300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.052900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.097100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.133700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.080300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.135200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.108100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.119800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.088000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.051900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.055400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.044300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.031300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.055200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.062700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.047700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.083900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.054400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.050500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.036300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.016600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.056700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.051900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.072400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.025600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.037700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.010900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.012800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.012500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.022600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.016400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.026100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.015900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.016400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.014900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 14:47:00,560] Trial 10 finished with value: 3.5025090662173017 and parameters: {'learning_rate': 3.337012376819092e-05, 'num_train_epochs': 10, 'weight_decay': 0.04851790132998138, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.10219717896396187}. Best is trial 10 with value: 3.5025090662173017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9550' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9550/9550 17:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.041700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.857600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.659400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.505400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.478500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.481800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.565300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.564400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.512000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.401400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.411900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.436000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.371500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.421100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.337400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.468700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.437900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.402700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.410600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.290100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.252100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.216800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.250600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.254200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.275500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.304900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.280300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.306100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.219800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.157700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.168400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.157300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.097800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.216800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.154900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.202500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.233000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.170500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.102500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.091400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.082400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.114600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.135500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.074200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.078100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.122800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.086200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.089600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.034700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.054700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.061300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.089300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.042700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.030900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.014300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.047700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.061500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.046700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.026400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.024200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.030500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.029100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.025600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.036500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.023500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.022600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.029400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.021300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.015400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.011300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 15:05:01,552] Trial 11 finished with value: 3.5024660165229964 and parameters: {'learning_rate': 3.53582283696454e-05, 'num_train_epochs': 10, 'weight_decay': 0.057232025923747945, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.1056323624153845}. Best is trial 10 with value: 3.5025090662173017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9550' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9550/9550 17:53, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.042500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.860400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.660900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.497500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.475600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.464100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.514700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.474000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.396900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.424500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.431800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.367800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.464300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.383300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.450200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.427800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.414100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.428500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.289900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.257200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.271000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.306400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.285400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.278600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.314800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.264800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.253000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.183300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.139600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.170700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.174700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.199700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.189200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.163800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.189600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.202000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.140700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.134100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.104700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.113100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.142000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.157400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.138600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.112700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.082400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.085400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.052800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.105800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.054700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.113200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.041200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.031300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.040400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.057500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.050600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.049700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.021700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.068700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.068300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.034200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.019500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.042800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.016000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.026900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.028200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.013900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.019800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.018700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.015900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.011300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.024000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.032800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.030700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 15:23:03,038] Trial 12 finished with value: 3.480170171562989 and parameters: {'learning_rate': 3.6622700279213506e-05, 'num_train_epochs': 10, 'weight_decay': 0.0031318537527858722, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.11175511516434884}. Best is trial 10 with value: 3.5025090662173017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9550' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9550/9550 17:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.044800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.666800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.498200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.469700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.481600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.535500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.505600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.477200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.390400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.363300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.392500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.369700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.481000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.334200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.433300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.344700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.367500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.262500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.244300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.182900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.186800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.265800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.281500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.288400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.271100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.312000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.160700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.108800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.133700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.189400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.179800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.148900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.174300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.059400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.093400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.085700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.104200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.044800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.110100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.124900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.106600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.085400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.074200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.078500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.055300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.075300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.039800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.052600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.054600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.058300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.025900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.049900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.052700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.045600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.057700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.019400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.030700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.045400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.024700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.039100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.035200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.037600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.019700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.017300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.015700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.012700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.010800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.014400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.023700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 15:41:04,064] Trial 13 finished with value: 3.4889847124002613 and parameters: {'learning_rate': 3.09985996511648e-05, 'num_train_epochs': 10, 'weight_decay': 0.08647983104176805, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.100008160813436}. Best is trial 10 with value: 3.5025090662173017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3820' max='3820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3820/3820 07:08, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.775900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.602000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.526800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.507700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.472500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.487000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.483700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.464600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.366900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.308900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.367300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.315300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.390500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.288700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.393000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.378400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.305800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.349200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.211400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.177700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.169200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.161000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.199700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.218700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.210100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.209400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.111600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.109900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.116800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.104700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.106500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.088600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.092500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.085700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-15 15:48:21,250] Trial 14 finished with value: 3.483893697732649 and parameters: {'learning_rate': 3.025450094301447e-05, 'num_train_epochs': 4, 'weight_decay': 0.006673195783167718, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.12229382211750621}. Best is trial 10 with value: 3.5025090662173017.\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter tuning\n",
        "best_trial = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    n_trials=15,\n",
        "    hp_space=hp_space,\n",
        "    backend=\"optuna\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dfe41403",
      "metadata": {
        "id": "dfe41403",
        "outputId": "2a008b5e-bc4e-4bbf-b1f2-e3ee50a78686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-20-2593341178>:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  best_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9550' max='9550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9550/9550 17:53, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.714900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.413800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.404000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.272400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.232100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.157200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.144300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.103300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.099900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.057300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.053100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.045900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.049100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.022000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.020200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.017500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.009300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9550, training_loss=0.17456924916381572, metrics={'train_runtime': 1073.2523, 'train_samples_per_second': 71.13, 'train_steps_per_second': 8.898, 'total_flos': 1858114150502652.0, 'train_loss': 0.17456924916381572, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Retrain with best trial\n",
        "best_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"no\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=float(best_trial.hyperparameters[\"learning_rate\"]),\n",
        "    per_device_train_batch_size=int(best_trial.hyperparameters[\"per_device_train_batch_size\"]),\n",
        "    num_train_epochs=int(best_trial.hyperparameters[\"num_train_epochs\"]),\n",
        "    weight_decay=float(best_trial.hyperparameters[\"weight_decay\"]),\n",
        "    warmup_ratio=float(best_trial.hyperparameters[\"warmup_ratio\"]),\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "best_model = model_init()\n",
        "best_trainer = Trainer(\n",
        "    model=best_model,\n",
        "    args=best_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics_transformers\n",
        ")\n",
        "\n",
        "best_trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e54b9e94",
      "metadata": {
        "id": "e54b9e94",
        "outputId": "fff4b24d-c7f1-4e57-8af9-049afb78227a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get predictions for train and val sets\n",
        "train_preds = best_trainer.predict(dataset[\"train\"])\n",
        "val_preds = best_trainer.predict(dataset[\"validation\"])\n",
        "\n",
        "train_labels = train_preds.label_ids\n",
        "train_pred_labels = np.argmax(train_preds.predictions, axis=1)\n",
        "\n",
        "val_labels = val_preds.label_ids\n",
        "val_pred_labels = np.argmax(val_preds.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fd9299f2",
      "metadata": {
        "id": "fd9299f2"
      },
      "outputs": [],
      "source": [
        "title = \"Best RoBERTa Model Performance (Optuna)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "575aa4db",
      "metadata": {
        "id": "575aa4db",
        "outputId": "2db358af-797f-4de3-8e4b-0e04569641b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                     Model  Train F1 (Macro)  Val F1 (Macro)  \\\n",
              "0  Best RoBERTa Model Performance (Optuna)            0.9989          0.8593   \n",
              "\n",
              "   Train Precision  Val Precision  Train Recall  Val Recall  Train Accuracy  \\\n",
              "0           0.9993         0.8597        0.9985       0.859          0.9992   \n",
              "\n",
              "   Val Accuracy  \n",
              "0        0.8921  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b954ada1-f1fb-4f03-b796-5199d1f0f6f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train F1 (Macro)</th>\n",
              "      <th>Val F1 (Macro)</th>\n",
              "      <th>Train Precision</th>\n",
              "      <th>Val Precision</th>\n",
              "      <th>Train Recall</th>\n",
              "      <th>Val Recall</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Val Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Best RoBERTa Model Performance (Optuna)</td>\n",
              "      <td>0.9989</td>\n",
              "      <td>0.8593</td>\n",
              "      <td>0.9993</td>\n",
              "      <td>0.8597</td>\n",
              "      <td>0.9985</td>\n",
              "      <td>0.859</td>\n",
              "      <td>0.9992</td>\n",
              "      <td>0.8921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b954ada1-f1fb-4f03-b796-5199d1f0f6f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b954ada1-f1fb-4f03-b796-5199d1f0f6f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b954ada1-f1fb-4f03-b796-5199d1f0f6f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_64048b35-d194-4f78-aa7d-4c9057cf19bc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_64048b35-d194-4f78-aa7d-4c9057cf19bc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metrics_df",
              "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Best RoBERTa Model Performance (Optuna)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train F1 (Macro)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9989,\n        \"max\": 0.9989,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9989\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val F1 (Macro)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8593,\n        \"max\": 0.8593,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9993,\n        \"max\": 0.9993,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8597,\n        \"max\": 0.8597,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8597\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9985,\n        \"max\": 0.9985,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.859,\n        \"max\": 0.859,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9992,\n        \"max\": 0.9992,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8921,\n        \"max\": 0.8921,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8921\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "metrics_df = get_metrics_df(title, train_labels, train_pred_labels, val_labels, val_pred_labels)\n",
        "display(metrics_df)\n",
        "\n",
        "plot_metrics(train_labels, train_pred_labels, val_labels, val_pred_labels, title=title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8fc606e6",
      "metadata": {
        "id": "8fc606e6",
        "outputId": "f3a46eba-f4e3-4c24-bbe9-d4538f621afb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./best_roberta_model/tokenizer_config.json',\n",
              " './best_roberta_model/special_tokens_map.json',\n",
              " './best_roberta_model/vocab.json',\n",
              " './best_roberta_model/merges.txt',\n",
              " './best_roberta_model/added_tokens.json',\n",
              " './best_roberta_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "output_path = \"./best_roberta_model\"\n",
        "best_model.save_pretrained(output_path)\n",
        "tokenizer.save_pretrained(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11fa0cbe",
      "metadata": {
        "id": "11fa0cbe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f03da179",
      "metadata": {
        "id": "f03da179"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "# **3.** **Final Predictions**\n",
        "\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1887dce",
      "metadata": {
        "id": "b1887dce"
      },
      "outputs": [],
      "source": [
        "# Load the test dataset\n",
        "test_data = pd.read_csv(\"../data/test.csv\")\n",
        "test_texts = test_data[\"text\"].tolist()\n",
        "\n",
        "# Get embeddings for test set\n",
        "X_test_roberta = np.array(get_roberta_embeddings(train_texts, \"X_test_roberta_embeddings.pkl\", batch_size=32, force_reload=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da07b55e",
      "metadata": {
        "id": "da07b55e"
      },
      "outputs": [],
      "source": [
        "# Predict labels with the trained classifier\n",
        "X_test_te3s_pred = clf_roberta_lr.predict(X_test_te3s)\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission_te3s = pd.DataFrame({\n",
        "    \"id\": test_data[\"id\"],\n",
        "    \"label\": X_test_roberta_pred\n",
        "})\n",
        "\n",
        "# Save submission to CSV\n",
        "submission_te3s.to_csv(\"roberta_lr_pred_25.csv\", index=False)\n",
        "print(\"Submission file saved as roberta_lr_pred_25.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef85b5ba",
      "metadata": {
        "id": "ef85b5ba"
      },
      "outputs": [],
      "source": [
        "# Load the predictions from the saved CSV file\n",
        "pred_25 = pd.read_csv(\"roberta_lr_pred_25.csv\")\n",
        "pred_25.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8652526a415d4c1bb0cc5ea1e2a42bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5af02d5492df486eb12e88d712076199",
              "IPY_MODEL_c36e4de72b1b4b17ac6ee067e3fd7528",
              "IPY_MODEL_3b90b2cae9b14e8999c103762f69beb6"
            ],
            "layout": "IPY_MODEL_1d2ceff3aa514da98ccb4f4725221e74"
          }
        },
        "5af02d5492df486eb12e88d712076199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2fd7c4e1ae04430b5340cc2e2692341",
            "placeholder": "​",
            "style": "IPY_MODEL_7f444f24985b4158ad86c47658cfc0b4",
            "value": "config.json: 100%"
          }
        },
        "c36e4de72b1b4b17ac6ee067e3fd7528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2767b3cd11e4a90be3e55d4abe5d32f",
            "max": 565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac050e4a28b540fd8d4e54f9c0fff20f",
            "value": 565
          }
        },
        "3b90b2cae9b14e8999c103762f69beb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e01b0005093747b685a5004b195b5a65",
            "placeholder": "​",
            "style": "IPY_MODEL_e134225350f74870817564cad3be4050",
            "value": " 565/565 [00:00&lt;00:00, 41.0kB/s]"
          }
        },
        "1d2ceff3aa514da98ccb4f4725221e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2fd7c4e1ae04430b5340cc2e2692341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f444f24985b4158ad86c47658cfc0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2767b3cd11e4a90be3e55d4abe5d32f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac050e4a28b540fd8d4e54f9c0fff20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e01b0005093747b685a5004b195b5a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e134225350f74870817564cad3be4050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22642c6ab81a4f56adbf9afda84b2742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_822a25ec3b984919ae550c3a93447e21",
              "IPY_MODEL_dea8aabee8914949a6c7d3f448e59b46",
              "IPY_MODEL_718f7b5a4481451ea7d8305908ed86fb"
            ],
            "layout": "IPY_MODEL_32c084f21c9a44f791e914dd691ae6ec"
          }
        },
        "822a25ec3b984919ae550c3a93447e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_764201c467884bd4aa0239977c1779eb",
            "placeholder": "​",
            "style": "IPY_MODEL_f7803a57344449bfa56a2906824ac700",
            "value": "vocab.json: 100%"
          }
        },
        "dea8aabee8914949a6c7d3f448e59b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dada733478241dbb6212c3489af7ddd",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b1e09ce806549b3ae162d63090d5fc2",
            "value": 898823
          }
        },
        "718f7b5a4481451ea7d8305908ed86fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5af9c3cc9c748aa9684da72d7fa5aac",
            "placeholder": "​",
            "style": "IPY_MODEL_243004813737486d9ed0ef33a6a535e8",
            "value": " 899k/899k [00:00&lt;00:00, 3.98MB/s]"
          }
        },
        "32c084f21c9a44f791e914dd691ae6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "764201c467884bd4aa0239977c1779eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7803a57344449bfa56a2906824ac700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dada733478241dbb6212c3489af7ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b1e09ce806549b3ae162d63090d5fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5af9c3cc9c748aa9684da72d7fa5aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243004813737486d9ed0ef33a6a535e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "563ab7e79e1e4d90ab93c7458e68a206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b6706d5815e4ed18a1d53dd0ea300b6",
              "IPY_MODEL_31bd11198dd647f9992af27bc58663f1",
              "IPY_MODEL_a0426b13ffeb40c29bc41ae76eef778c"
            ],
            "layout": "IPY_MODEL_6ec3b8a77f614f419e895e919488774f"
          }
        },
        "3b6706d5815e4ed18a1d53dd0ea300b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01f793e12e954d77bd510dc2a2f73504",
            "placeholder": "​",
            "style": "IPY_MODEL_b42dcc4389004c69b9a7f0e24d0c613a",
            "value": "merges.txt: 100%"
          }
        },
        "31bd11198dd647f9992af27bc58663f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab000a4cabc7405f942c46018c2a8d5f",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56bc2282a5c04b048e63b8a290a771e5",
            "value": 456318
          }
        },
        "a0426b13ffeb40c29bc41ae76eef778c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fd5bd21a7224d80b57d7020d7a4f44c",
            "placeholder": "​",
            "style": "IPY_MODEL_1bfb359b888049098f3035c9a8d324a8",
            "value": " 456k/456k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "6ec3b8a77f614f419e895e919488774f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f793e12e954d77bd510dc2a2f73504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42dcc4389004c69b9a7f0e24d0c613a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab000a4cabc7405f942c46018c2a8d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56bc2282a5c04b048e63b8a290a771e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fd5bd21a7224d80b57d7020d7a4f44c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfb359b888049098f3035c9a8d324a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22f1857826d74eb28c79b87e88f3e96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b69be265b54da5b252d39407a1086e",
              "IPY_MODEL_4f903aa67a544f24989ff7c52fcca017",
              "IPY_MODEL_fd9662a3f97a48c6bac159be44714bd8"
            ],
            "layout": "IPY_MODEL_a21af05d32084e34a9dd91559d9f98a5"
          }
        },
        "b3b69be265b54da5b252d39407a1086e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120eb0a5883c4df3b13ed4c69942b9a7",
            "placeholder": "​",
            "style": "IPY_MODEL_03e069f1b8bd45c1922deacb065b3199",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4f903aa67a544f24989ff7c52fcca017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e78c97bf95468997519ecefdf5e8cd",
            "max": 501204462,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20aaacf704ce45fbb7ace72ece95c2d9",
            "value": 501204462
          }
        },
        "fd9662a3f97a48c6bac159be44714bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0874a1811648c69a3b94e8f93ea5ce",
            "placeholder": "​",
            "style": "IPY_MODEL_1df74b761ce340dd9789b3a32a7b6996",
            "value": " 501M/501M [00:01&lt;00:00, 273MB/s]"
          }
        },
        "a21af05d32084e34a9dd91559d9f98a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120eb0a5883c4df3b13ed4c69942b9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e069f1b8bd45c1922deacb065b3199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e78c97bf95468997519ecefdf5e8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20aaacf704ce45fbb7ace72ece95c2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc0874a1811648c69a3b94e8f93ea5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df74b761ce340dd9789b3a32a7b6996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1063d3ca8d7944c5b26cfa8a086d20d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da47443854144949aa55b6a14182cdb8",
              "IPY_MODEL_3701e0ce90f2487fbd6fe48e06d66be6",
              "IPY_MODEL_f6205addc9084f3b80d931318b590f45"
            ],
            "layout": "IPY_MODEL_6c8580a8999348f798dae83165ad73cb"
          }
        },
        "da47443854144949aa55b6a14182cdb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a248cd7030934f7ab6017b1ce18d1f1c",
            "placeholder": "​",
            "style": "IPY_MODEL_8e219413361f499fab71476fa3f0727f",
            "value": "Map: 100%"
          }
        },
        "3701e0ce90f2487fbd6fe48e06d66be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804881289c234d2ebbdf89c24875e5d1",
            "max": 7634,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba82667307f84792a4ebd473b93e35a9",
            "value": 7634
          }
        },
        "f6205addc9084f3b80d931318b590f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b8c5a01ff1f42ed99d95b0af499546d",
            "placeholder": "​",
            "style": "IPY_MODEL_dcd1d0b482c84fb1a4947c59f6e8ba60",
            "value": " 7634/7634 [00:01&lt;00:00, 5264.88 examples/s]"
          }
        },
        "6c8580a8999348f798dae83165ad73cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a248cd7030934f7ab6017b1ce18d1f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e219413361f499fab71476fa3f0727f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "804881289c234d2ebbdf89c24875e5d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba82667307f84792a4ebd473b93e35a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b8c5a01ff1f42ed99d95b0af499546d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd1d0b482c84fb1a4947c59f6e8ba60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f612896c7bb649d187d63529f2ce1bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30175b61227d4a3abb4e1e4ec7650f5e",
              "IPY_MODEL_50abf622a6cd45fc909a5f40f35d0b0e",
              "IPY_MODEL_151162f8d1a3437193e732c6ee113b2c"
            ],
            "layout": "IPY_MODEL_8b62ca14580f43689eaee31d727754d0"
          }
        },
        "30175b61227d4a3abb4e1e4ec7650f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a251b2f8a7964d35824319f5d3d89a26",
            "placeholder": "​",
            "style": "IPY_MODEL_6571afeefde4448abe78706dba974bfb",
            "value": "model.safetensors: 100%"
          }
        },
        "50abf622a6cd45fc909a5f40f35d0b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc0312b87a24c21acf0227f3d2ea861",
            "max": 501176510,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1675575dc3e43da90abf1a627fea230",
            "value": 501176510
          }
        },
        "151162f8d1a3437193e732c6ee113b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb9441dfd17343df835fa80aac6a6c50",
            "placeholder": "​",
            "style": "IPY_MODEL_794627cd93d54f478515b66ba0aaaa40",
            "value": " 501M/501M [00:03&lt;00:00, 195MB/s]"
          }
        },
        "8b62ca14580f43689eaee31d727754d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a251b2f8a7964d35824319f5d3d89a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6571afeefde4448abe78706dba974bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cc0312b87a24c21acf0227f3d2ea861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1675575dc3e43da90abf1a627fea230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb9441dfd17343df835fa80aac6a6c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794627cd93d54f478515b66ba0aaaa40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cea4be600a740fdb9c2594e62840b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6195c30992fa470f8e670dc21ff72539",
              "IPY_MODEL_c51c1d10ddce478cbd9df4fe2d87f5da",
              "IPY_MODEL_0b1904d18dee46e6862846ec34f3a408"
            ],
            "layout": "IPY_MODEL_47421a189993489097126178f3e15383"
          }
        },
        "6195c30992fa470f8e670dc21ff72539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27c9a826cccf4a4d8b61c734405b0977",
            "placeholder": "​",
            "style": "IPY_MODEL_e70b4a1e2ba64a75aa9fc7b53e249919",
            "value": "Map: 100%"
          }
        },
        "c51c1d10ddce478cbd9df4fe2d87f5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1dd713695184a919c7e901ae7bb1bfb",
            "max": 1909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d549f71a0c57477088fe3068f864074e",
            "value": 1909
          }
        },
        "0b1904d18dee46e6862846ec34f3a408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72df9e13fe24feaba5594f723ee1fe2",
            "placeholder": "​",
            "style": "IPY_MODEL_e280b9d0c85b47e594467f80d61d7ae8",
            "value": " 1909/1909 [00:00&lt;00:00, 3931.83 examples/s]"
          }
        },
        "47421a189993489097126178f3e15383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c9a826cccf4a4d8b61c734405b0977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70b4a1e2ba64a75aa9fc7b53e249919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1dd713695184a919c7e901ae7bb1bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d549f71a0c57477088fe3068f864074e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e72df9e13fe24feaba5594f723ee1fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e280b9d0c85b47e594467f80d61d7ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}